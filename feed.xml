<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>WillEdTech</title>
    <link href="https://willedtech.github.io/feed.xml" rel="self" />
    <link href="https://willedtech.github.io" />
    <updated>2024-09-08T22:34:24-05:00</updated>
    <author>
        <name>William Humberto Herrera Rey</name>
    </author>
    <id>https://willedtech.github.io</id>

    <entry>
        <title>Deteniendo al perrito</title>
        <author>
            <name>William Humberto Herrera Rey</name>
        </author>
        <link href="https://willedtech.github.io/deteniendo-al-perrito/"/>
        <id>https://willedtech.github.io/deteniendo-al-perrito/</id>
        <media:content url="https://willedtech.github.io/media/posts/1/Snapshot.PNG" medium="image" />
            <category term="Proyecto de Imágenes"/>

        <updated>2024-09-08T21:54:59-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://willedtech.github.io/media/posts/1/Snapshot.PNG" alt="" />
                    En el mundo de la inteligencia artificial (IA), las aplicaciones prácticas y&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://willedtech.github.io/media/posts/1/Snapshot.PNG" class="type:primaryImage" alt="" /></p>
                <p>En el mundo de la inteligencia artificial (IA), las aplicaciones prácticas y creativas están en constante expansión. Una de las herramientas más innovadoras que he encontrado recientemente es <a href="https://playground.raise.mit.edu/" target="_blank" class="extlink extlink-icon-1 "  rel="noopener noreferrer">POSEBLOCKS</a>, un proyecto del MIT Media Lab Personal Robots Group que permite a los usuarios diseñar sistemas interactivos de IA basados en el movimiento.</p>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/26nkbr0x3tE?si=TkZXPpTGMNgqDkLp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe></div>
<div class="post__toc">
<h3>Tabla de contenidos</h3>
<ul>
<li><a href="#mcetoc_1i7ackmeq3c">Aplicación: </a></li>
<li><a href="#mcetoc_1i7ackmeq3d">Beneficios Educativos</a></li>
<li><a href="#mcetoc_1i7ackmeq3e">Conclusión</a>
<ul>
<li><a href="#mcetoc_1i7actnb73q">Ejemplo de uso</a></li>
</ul>
</li>
</ul>
</div>
<hr>
<h3 id="mcetoc_1i7ackmeq3c">Aplicación: </h3>
<p>Una de las aplicaciones más fascinantes de esta tecnología es el control del movimiento de un perrito virtual al poner o quitar la mano de la cara. Aquí te explico cómo funciona:</p>
<ol>
<li><strong>Configuración Inicial: </strong>Utilizando PoseNet, se puede rastrear la posición de la mano y la cara del usuario. PoseNet es un modelo de aprendizaje automático que puede detectar las posiciones de varias partes del cuerpo en tiempo real.</li>
<li><strong>Entrenamiento del Modelo: </strong>Con <a href="https://teachablemachine.withgoogle.com/" target="_blank" class="extlink extlink-icon-1 "  rel="noopener noreferrer">Teachable Machine</a>, se entrena un modelo para reconocer dos estados: mano en la cara y mano fuera de la cara. Este modelo se integra en el proyecto de PoseNet para que pueda reaccionar a estos gestos específicos.</li>
<li><strong>Interacción con el Perrito Virtual: </strong>Una vez que el modelo está entrenado, se programa para que el perrito virtual realice diferentes movimientos según la posición de la mano. Por ejemplo, si la mano está en la cara, el perrito puede sentarse; si la mano se quita de la cara, el perrito puede empezar a caminar.</li>
</ol>
<h3 id="mcetoc_1i7ackmeq3d"><strong>Beneficios Educativos</strong></h3>
<p>Este tipo de proyecto no solo es divertido y creativo, sino que también tiene un gran valor educativo. Los estudiantes aprenden sobre el entrenamiento de modelos de IA, la detección de poses y la programación de interacciones complejas. Además, fomenta el pensamiento crítico sobre cómo interactuamos con la IA y las posibles aplicaciones en la vida real.</p>
<h3 id="mcetoc_1i7ackmeq3e"><strong>Conclusión</strong></h3>
<p>Esta tecnología abre un mundo de posibilidades para la creación de proyectos interactivos basados en el movimiento. Controlar el movimiento de un perrito virtual con simples gestos de la mano es solo una de las muchas aplicaciones posibles.</p>
<blockquote>
<p class="align-center"><em>¡Anímate a explorar y crear tus propias experiencias interactivas con esta increíble herramienta!</em></p>
</blockquote>
<h4 id="mcetoc_1i7actnb73q">Ejemplo de uso</h4>
<ol>
<li>Ingrese a <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-1 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li>Descargue el archivo <a href="https://willedtech.github.io/media/files/Deteniendo al Perrito.sb3">Deteniendo al Perrito.sb3</a></li>
<li>Cargue el archivo en la plataforma.</li>
<li>Inicie simulación en la Banderita Verde.</li>
</ol>
            ]]>
        </content>
    </entry>
</feed>
