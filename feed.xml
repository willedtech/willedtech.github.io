<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>WillEdTech</title>
    <link href="https://willedtech.github.io/feed.xml" rel="self" />
    <link href="https://willedtech.github.io" />
    <updated>2024-09-16T15:17:15-05:00</updated>
    <author>
        <name>William Humberto Herrera Rey</name>
    </author>
    <id>https://willedtech.github.io</id>

    <entry>
        <title>Me Siento</title>
        <author>
            <name>William Humberto Herrera Rey</name>
        </author>
        <link href="https://willedtech.github.io/me-siento/"/>
        <id>https://willedtech.github.io/me-siento/</id>
        <media:content url="https://willedtech.github.io/media/posts/6/Me-Siento.gif" medium="image" />

        <updated>2024-09-16T15:11:27-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://willedtech.github.io/media/posts/6/Me-Siento.gif" alt="" />
                    En la era digital, la Inteligencia Artificial (IA) ha revolucionado la forma&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://willedtech.github.io/media/posts/6/Me-Siento.gif" class="type:primaryImage" alt="" /></p>
                <p>En la era digital, la Inteligencia Artificial (IA) ha revolucionado la forma en que interactuamos con la tecnología. Una de las aplicaciones más fascinantes es el uso de <strong><a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a></strong> para realizar cambios de imagen basados en los gestos del rostro. En este artículo, exploraremos cómo esta tecnología hace posible esta experiencia y cómo puede implementarse pedagógicamente.</p>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/b7kibjbV9lo?si=oJcX5Q66EGUOmgBD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe></div>
<div class="post__toc">
<h3>Tabla de contenidos</h3>
<ul>
<li><a href="#mcetoc_1i7u7c4tdk">¿Qué es PoseNet?</a></li>
<li><a href="#mcetoc_1i7u7c4tdl">¿Cómo Funciona el Cambio de Imagen con Gestos del Rostro?</a></li>
<li><a href="#mcetoc_1i7u7c4tdm">Implementación Pedagógica</a></li>
<li><a href="#mcetoc_1i7u7c4tdn">Conclusión</a>
<ul>
<li><a href="#mcetoc_1i7actnb73q">Ejemplo de uso</a></li>
</ul>
</li>
</ul>
</div>
<h3 id="mcetoc_1i7u7c4tdk">¿Qué es PoseNet?</h3>
<p><strong><a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a></strong> es un modelo de visión por computadora que permite detectar las posiciones de las articulaciones del cuerpo humano en tiempo real. Desarrollado por Google, PoseNet utiliza redes neuronales para identificar puntos clave en el cuerpo, como los ojos, la nariz, los hombros, los codos, entre otros. Esta capacidad de detección precisa es lo que permite crear experiencias interactivas y dinámicas.</p>
<h3 id="mcetoc_1i7u7c4tdl" class="align-center">¿Cómo Funciona el Cambio de Imagen con Gestos del Rostro?</h3>
<p>El cambio de imagen con gestos del rostro se basa en la capacidad de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> para rastrear y analizar los movimientos faciales. Aquí hay un desglose de cómo funciona:</p>
<ol>
<li><strong>Detección de Puntos Clave</strong>: <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> identifica y rastrea puntos clave en el rostro del usuario en tiempo real.</li>
<li><strong>Análisis de Gestos</strong>: Los gestos faciales, como sonreír, fruncir el ceño o levantar las cejas, son analizados y categorizados.</li>
<li><strong>Aplicación de Filtros</strong>: Basado en el análisis de los gestos, se aplican filtros o efectos visuales que transforman la apariencia del rostro del usuario. Esto puede incluir cambios en el color del cabello, maquillaje virtual, o incluso la adición de accesorios como gafas o sombreros.</li>
</ol>
<h3 id="mcetoc_1i7u7c4tdm">Implementación Pedagógica</h3>
<p>La implementación de esta tecnología en un entorno educativo puede ser altamente beneficiosa. Aquí hay algunas ideas sobre cómo se puede utilizar pedagógicamente:</p>
<ol>
<li><strong>Clases de Arte y Diseño</strong>: Los estudiantes pueden usar <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> para experimentar con diferentes estilos de arte y diseño gráfico, aplicando cambios de imagen virtuales a sus retratos.</li>
<li><strong>Educación en Tecnología</strong>: Enseñar a los estudiantes sobre IA y visión por computadora mediante la creación de proyectos interactivos que utilicen <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li><strong>Desarrollo de Habilidades Sociales</strong>: Utilizar la tecnología para ayudar a los estudiantes a comprender y practicar la lectura de expresiones faciales y emociones, mejorando sus habilidades de comunicación interpersonal.</li>
<li><strong>Proyectos Interdisciplinarios</strong>: Integrar <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> en proyectos que combinen arte, tecnología y ciencias sociales, fomentando la creatividad y el pensamiento crítico.</li>
</ol>
<h3 id="mcetoc_1i7u7c4tdn">Conclusión</h3>
<p>El uso de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la Inteligencia Artificial para realizar cambios de imagen basados en gestos del rostro no solo es una experiencia divertida e innovadora, sino que también ofrece numerosas oportunidades pedagógicas.</p>
<blockquote>
<p>Al integrar esta tecnología en el aula, los educadores pueden proporcionar a los estudiantes herramientas para explorar y aprender de manera interactiva y dinámica.</p>
</blockquote>
<h4 id="mcetoc_1i7actnb73q">Ejemplo de uso</h4>
<ol>
<li>Ingrese a <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li>Descargue el archivo <a href="https://willedtech.github.io/media/files/Me-siento.sb3" target="_blank" rel="noopener noreferrer">Me siento.sb3</a></li>
<li>Cargue el archivo en la plataforma.</li>
<li>Inicie simulación en la Banderita Verde.</li>
</ol>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Loro Volador</title>
        <author>
            <name>William Humberto Herrera Rey</name>
        </author>
        <link href="https://willedtech.github.io/loro-volador/"/>
        <id>https://willedtech.github.io/loro-volador/</id>
        <media:content url="https://willedtech.github.io/media/posts/5/Loro-Volador.gif" medium="image" />
            <category term="Proyecto de Imágenes"/>

        <updated>2024-09-11T08:33:08-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://willedtech.github.io/media/posts/5/Loro-Volador.gif" alt="" />
                    ¿Alguna vez has imaginado controlar un loro pirata con solo tus gestos&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://willedtech.github.io/media/posts/5/Loro-Volador.gif" class="type:primaryImage" alt="" /></p>
                <p>¿Alguna vez has imaginado controlar un loro pirata con solo tus gestos faciales? Gracias a la combinación de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la Inteligencia Artificial (IA), esta fantasía puede convertirse en realidad. En esta publicación, exploraremos cómo esta tecnología hace posible esta experiencia y cómo puede ser implementada pedagógicamente en el aula.</p>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/2_5w1m5U8JU?si=uQtUxuUE4lhfd97H" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe></div>
<div class="post__toc">
<h3>Tabla de contenidos</h3>
<ul>
<li><a href="#mcetoc_1i7gkh3i7k">¿Qué es PoseNet?</a></li>
<li><a href="#mcetoc_1i7gkh3i7l">La Magia Detrás del Loro Pirata</a></li>
<li><a href="#mcetoc_1i7gkh3i7m">Implementación Pedagógica</a></li>
<li><a href="#mcetoc_1i7gkh3i7n">Conclusión</a></li>
</ul>
</div>
<h3 id="mcetoc_1i7gkh3i7k">¿Qué es <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>?</h3>
<p><a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> es una aplicación de Visión por Computador que utiliza redes neuronales convolucionales (CNN) para detectar la postura y los movimientos del cuerpo humano en tiempo real. Originalmente diseñada para identificar posiciones corporales, <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> se ha adaptado para reconocer gestos faciales, como el movimiento de los ojos y las cejas.</p>
<h3 id="mcetoc_1i7gkh3i7l">La Magia Detrás del Loro Pirata</h3>
<p>Para crear un loro pirata que responda a tus gestos faciales, se necesita una combinación de hardware y software:</p>
<ol>
<li><strong>Cámara Web</strong>: Captura los movimientos faciales en tiempo real.</li>
<li><strong>PoseNet</strong>: Analiza los datos de la cámara y detecta los gestos faciales.</li>
<li><strong>Modelo de IA</strong>: Interpreta los gestos y los traduce en movimientos del loro pirata.</li>
<li><strong>Software de Animación</strong>: Controla el modelo 3D del loro pirata, haciendo que responda a los gestos detectados.</li>
</ol>
<h3 id="mcetoc_1i7gkh3i7m">Implementación Pedagógica</h3>
<p>La integración de esta tecnología en el aula puede tener múltiples beneficios educativos:</p>
<ol>
<li><strong>Fomento de la Creatividad</strong>: Los estudiantes pueden diseñar sus propios personajes y controlar sus movimientos, fomentando la creatividad y el pensamiento crítico.</li>
<li><strong>Aprendizaje Interactivo</strong>: La interacción con personajes animados puede hacer que el aprendizaje sea más atractivo y divertido.</li>
<li><strong>Desarrollo de Habilidades Técnicas</strong>: Los estudiantes pueden aprender sobre Visión por Computador, IA y programación mientras crean y controlan sus personajes.</li>
<li><strong>Inclusión</strong>: Esta tecnología puede ser utilizada para crear experiencias de aprendizaje inclusivas, permitiendo a estudiantes con discapacidades motoras interactuar con el contenido educativo de nuevas maneras.</li>
</ol>
<h3 id="mcetoc_1i7gkh3i7n">Conclusión</h3>
<p>El uso de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la IA para controlar un loro pirata con gestos faciales es una muestra fascinante de cómo la tecnología puede transformar la educación. No solo hace que el aprendizaje sea más interactivo y divertido, sino que también abre nuevas oportunidades para el desarrollo de habilidades técnicas y creativas en los estudiantes.</p>
<blockquote>
<p>¡Atrévete y haz caras divertidas!</p>
</blockquote>
<h4 id="mcetoc_1i7actnb73q">Ejemplo de uso</h4>
<ol>
<li>Ingrese a <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li>Descargue el archivo <a href="https://willedtech.github.io/media/files/Loro-Volador.sb3" target="_blank" rel="noopener noreferrer">Loro Volador.sb3</a></li>
<li>Cargue el archivo en la plataforma.</li>
<li>Inicie simulación en la Banderita Verde.</li>
</ol>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Pinza para pintar, nariz para borrar</title>
        <author>
            <name>William Humberto Herrera Rey</name>
        </author>
        <link href="https://willedtech.github.io/pinza-para-pintar-nariz-para-borrar/"/>
        <id>https://willedtech.github.io/pinza-para-pintar-nariz-para-borrar/</id>
        <media:content url="https://willedtech.github.io/media/posts/4/Pinza-Para-Pintar-Nariz-Para-Borrar.gif" medium="image" />
            <category term="Proyecto de Imágenes"/>

        <updated>2024-09-10T13:47:42-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://willedtech.github.io/media/posts/4/Pinza-Para-Pintar-Nariz-Para-Borrar.gif" alt="" />
                    PoseNet es un modelo de Visión por Computador que utiliza redes neuronales&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://willedtech.github.io/media/posts/4/Pinza-Para-Pintar-Nariz-Para-Borrar.gif" class="type:primaryImage" alt="" /></p>
                <p><a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> es un modelo de Visión por Computador que utiliza redes neuronales convolucionales (CNN) para detectar las posiciones de las articulaciones del cuerpo humano en imágenes y videos. Esta tecnología puede identificar puntos clave como los codos, las rodillas y, por supuesto, los dedos y la nariz.</p>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/687nnTwQiU0?si=eCXNzcaVUvLPOz_G" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe></div>
<div class="post__toc">
<h3>Tabla de contenidos</h3>
<ul>
<li><a href="#mcetoc_1i7ekc1nn66">Aplicación Práctica: Control de Aerosoles</a></li>
<li><a href="#mcetoc_1i7ekc1nn67">Borrar con la Nariz</a></li>
<li><a href="#mcetoc_1i7ekc1nn68">Beneficios y Aplicaciones</a></li>
<li><a href="#mcetoc_1i7ekc1nn69">Conclusión</a>
<ul>
<li><a href="#mcetoc_1i7actnb73q">Ejemplo de uso</a></li>
</ul>
</li>
</ul>
</div>
<h3 id="mcetoc_1i7ekc1nn66">Aplicación Práctica: Control de Aerosoles</h3>
<p>Imagina un escenario donde puedes controlar un aerosol simplemente moviendo tu dedo índice. Con <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>, esto es posible. Aquí te mostramos cómo:</p>
<ol>
<li><strong>Configuración Inicial</strong>: Instala <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> en tu dispositivo y asegúrate de que la cámara esté bien posicionada para capturar tus movimientos.</li>
<li><strong>Detección del Dedo Índice</strong>: Utiliza <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> para identificar la posición de tu dedo índice. Puedes programar la aplicación para que reconozca cuando tu dedo índice está en una posición específica y, en ese momento, activar el aerosol.</li>
<li><strong>Rociar el Aerosol</strong>: Una vez que <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> detecte la posición correcta de tu dedo índice, un microcontrolador puede enviar una señal para activar el aerosol, permitiéndote rociar con precisión.</li>
</ol>
<h3 id="mcetoc_1i7ekc1nn67">Borrar con la Nariz</h3>
<p>Además de controlar el aerosol, también puedes usar <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> para borrar con la nariz. Este es un proceso similar:</p>
<ol>
<li><strong>Detección de la Nariz</strong>: Configura <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet </a>para identificar la posición de tu nariz.</li>
<li><strong>Acción de Borrado</strong>: Programa la aplicación para que, cuando tu nariz se mueva a una posición específica, se active una función de borrado en una pizarra digital o cualquier otra superficie interactiva.</li>
</ol>
<h3 id="mcetoc_1i7ekc1nn68">Beneficios y Aplicaciones</h3>
<p>El uso de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la IA para estas tareas tiene múltiples beneficios:</p>
<ul>
<li><strong>Precisión</strong>: La detección de posturas permite un control preciso y eficiente.</li>
<li><strong>Interactividad</strong>: Hace que la interacción con dispositivos sea más intuitiva y natural.</li>
<li><strong>Innovación</strong>: Abre nuevas posibilidades en campos como la educación, la salud y el entretenimiento.</li>
</ul>
<h3 id="mcetoc_1i7ekc1nn69">Conclusión</h3>
<p>La combinación de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la Inteligencia Artificial está transformando la manera en que interactuamos con el mundo. Desde controlar aerosoles con el dedo índice hasta borrar con la nariz, las posibilidades son infinitas.</p>
<blockquote>
<p>¡La tecnología está aquí para hacer nuestras vidas más fáciles y emocionantes!</p>
</blockquote>
<h4 id="mcetoc_1i7actnb73q">Ejemplo de uso</h4>
<ol>
<li>Ingrese a <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li>Descargue el archivo <a href="https://willedtech.github.io/media/files/Pinza para pintar, nariz para borrar.sb3" target="_blank" rel="noopener noreferrer">Pinza para pintar, nariz para borrar.sb3</a></li>
<li>Cargue el archivo en la plataforma.</li>
<li>Inicie simulación en la Banderita Verde.</li>
</ol>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Dibujando con los dedos</title>
        <author>
            <name>William Humberto Herrera Rey</name>
        </author>
        <link href="https://willedtech.github.io/dibujando-con-los-dedos/"/>
        <id>https://willedtech.github.io/dibujando-con-los-dedos/</id>
        <media:content url="https://willedtech.github.io/media/posts/3/Dibujando-Con-Los-Dedos.gif" medium="image" />
            <category term="Proyecto de Imágenes"/>

        <updated>2024-09-10T08:32:21-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://willedtech.github.io/media/posts/3/Dibujando-Con-Los-Dedos.gif" alt="" />
                    En la era digital, la creatividad y la tecnología se entrelazan de&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://willedtech.github.io/media/posts/3/Dibujando-Con-Los-Dedos.gif" class="type:primaryImage" alt="" /></p>
                <p>En la era digital, la creatividad y la tecnología se entrelazan de maneras fascinantes. Una de las innovaciones más emocionantes es la capacidad de dibujar y borrar utilizando solo nuestros dedos, gracias a aplicaciones como <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la inteligencia artificial (IA). En este artículo, exploraremos cómo puedes aprovechar estas herramientas para crear arte digital de una manera intuitiva y divertida.</p>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/Kb4d2fQQi-g?si=zLmepJ0cTbGtK_kJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe></div>
<div class="post__toc">
<h3>Tabla de contenidos</h3>
<ul>
<li><a href="#mcetoc_1i7e1vml25">¿Qué es PoseNet?</a></li>
<li><a href="#mcetoc_1i7e24t6v1n">Cómo Funciona</a></li>
<li><a href="#mcetoc_1i7e24t6v1o">Beneficios de Usar IA en el Arte Digital</a></li>
<li><a href="#mcetoc_1i7e24t6v1p">Conclusión</a>
<ul>
<li><a href="#mcetoc_1i7actnb73q">Ejemplo de uso</a></li>
</ul>
</li>
</ul>
</div>
<h3 id="mcetoc_1i7e1vml25">¿Qué es <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>?<br><a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer"></a></h3>
<p><a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet </a>es un modelo de aprendizaje automático que puede detectar la posición de las partes del cuerpo en tiempo real utilizando la cámara de tu dispositivo. Originalmente desarrollado por Google, <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> es capaz de identificar puntos clave en el cuerpo humano, como los codos, las rodillas y, por supuesto, los dedos.</p>
<h3 id="mcetoc_1i7e24t6v1n">Cómo Funciona</h3>
<ul>
<li><strong>Configuración Inicial:</strong> Para empezar, necesitas una cámara web y acceso a la aplicación <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>. Puedes encontrar implementaciones de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> en varias plataformas, incluyendo <a href="https://www.tensorflow.org/?hl=es-419" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">TensorFlow.js</a>, que permite ejecutar el modelo directamente en tu navegador.</li>
<li><strong>Dibujar con el Dedo Índice: </strong>Una vez que <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> está configurado, puedes usar tu dedo índice como un pincel. La aplicación detecta la posición de tu dedo y traza líneas en la pantalla siguiendo tus movimientos. Es como tener un pincel invisible que responde a cada gesto.</li>
<li><strong>Borrar con el Dedo Pulgar: </strong>Para borrar, simplemente usa tu dedo pulgar. La aplicación puede ser programada para reconocer cuando el pulgar toca la pantalla y activar la función de borrado. Esto permite una transición fluida entre dibujar y borrar, haciendo que el proceso creativo sea más natural.</li>
</ul>
<h3 id="mcetoc_1i7e24t6v1o">Beneficios de Usar IA en el Arte Digital</h3>
<ul>
<li><strong>Precisión y Control: </strong>La IA permite una detección precisa de los movimientos, lo que se traduce en un control detallado sobre el dibujo.</li>
<li><strong>Interactividad:</strong> Usar tus dedos para dibujar y borrar hace que la experiencia sea más interactiva y envolvente.</li>
<li><strong>Accesibilidad: </strong>Esta tecnología puede ser especialmente útil para personas con discapacidades, ya que elimina la necesidad de herramientas físicas como lápices o pinceles.</li>
</ul>
<h3 id="mcetoc_1i7e24t6v1p"><strong>Conclusión</strong></h3>
<p>La combinación de <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a> y la inteligencia artificial abre un mundo de posibilidades para los artistas digitales. Dibujar con el dedo índice y borrar con el pulgar no solo es una forma innovadora de crear arte, sino que también hace que el proceso sea más accesible y divertido.</p>
<blockquote>
<p>¡Si aún no has probado esta tecnología, te animo a que lo hagas y descubras una nueva dimensión de la creatividad!</p>
</blockquote>
<h4 id="mcetoc_1i7actnb73q">Ejemplo de uso</h4>
<ol>
<li>Ingrese a <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li>Descargue el archivo <a href="https://willedtech.github.io/media/files/Controlando con los dedos.sb3" target="_blank" rel="noopener noreferrer">Controlando con los dedos.sb3</a><a href="https://willedtech.github.io/media/files/Deteniendo al Perrito.sb3" target="null"></a></li>
<li>Cargue el archivo en la plataforma.</li>
<li>Inicie simulación en la Banderita Verde.</li>
</ol>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Deteniendo al perrito</title>
        <author>
            <name>William Humberto Herrera Rey</name>
        </author>
        <link href="https://willedtech.github.io/deteniendo-al-perrito/"/>
        <id>https://willedtech.github.io/deteniendo-al-perrito/</id>
        <media:content url="https://willedtech.github.io/media/posts/1/Deteniendo-Al-Perrito.gif" medium="image" />
            <category term="Proyecto de Imágenes"/>

        <updated>2024-09-08T21:54:59-05:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://willedtech.github.io/media/posts/1/Deteniendo-Al-Perrito.gif" alt="" />
                    En el mundo de la inteligencia artificial (IA), las aplicaciones prácticas y&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://willedtech.github.io/media/posts/1/Deteniendo-Al-Perrito.gif" class="type:primaryImage" alt="" /></p>
                <p>En el mundo de la inteligencia artificial (IA), las aplicaciones prácticas y creativas están en constante expansión. Una de las herramientas más innovadoras que he encontrado recientemente es <a href="https://playground.raise.mit.edu/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">POSEBLOCKS</a>, un proyecto del MIT Media Lab Personal Robots Group que permite a los usuarios diseñar sistemas interactivos de IA basados en el movimiento.</p>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/26nkbr0x3tE?si=TkZXPpTGMNgqDkLp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe></div>
<div class="post__toc">
<h3>Tabla de contenidos</h3>
<ul>
<li><a href="#mcetoc_1i7ackmeq3c">Aplicación: </a></li>
<li><a href="#mcetoc_1i7ackmeq3d">Beneficios Educativos</a></li>
<li><a href="#mcetoc_1i7ackmeq3e">Conclusión</a>
<ul>
<li><a href="#mcetoc_1i7actnb73q">Ejemplo de uso</a></li>
</ul>
</li>
</ul>
</div>
<hr>
<h3 id="mcetoc_1i7ackmeq3c">Aplicación: </h3>
<p>Una de las aplicaciones más fascinantes de esta tecnología es el control del movimiento de un perrito virtual al poner o quitar la mano de la cara. Aquí te explico cómo funciona:</p>
<ol>
<li><strong>Configuración Inicial: </strong>Utilizando PoseNet, se puede rastrear la posición de la mano y la cara del usuario. PoseNet es un modelo de aprendizaje automático que puede detectar las posiciones de varias partes del cuerpo en tiempo real.</li>
<li><strong>Entrenamiento del Modelo: </strong>Con <a href="https://teachablemachine.withgoogle.com/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">Teachable Machine</a>, se entrena un modelo para reconocer dos estados: mano en la cara y mano fuera de la cara. Este modelo se integra en el proyecto de PoseNet para que pueda reaccionar a estos gestos específicos.</li>
<li><strong>Interacción con el Perrito Virtual: </strong>Una vez que el modelo está entrenado, se programa para que el perrito virtual realice diferentes movimientos según la posición de la mano. Por ejemplo, si la mano está en la cara, el perrito puede sentarse; si la mano se quita de la cara, el perrito puede empezar a caminar.</li>
</ol>
<h3 id="mcetoc_1i7ackmeq3d"><strong>Beneficios Educativos</strong></h3>
<p>Este tipo de proyecto no solo es divertido y creativo, sino que también tiene un gran valor educativo. Los estudiantes aprenden sobre el entrenamiento de modelos de IA, la detección de poses y la programación de interacciones complejas. Además, fomenta el pensamiento crítico sobre cómo interactuamos con la IA y las posibles aplicaciones en la vida real.</p>
<h3 id="mcetoc_1i7ackmeq3e"><strong>Conclusión</strong></h3>
<p>Esta tecnología abre un mundo de posibilidades para la creación de proyectos interactivos basados en el movimiento. Controlar el movimiento de un perrito virtual con simples gestos de la mano es solo una de las muchas aplicaciones posibles.</p>
<blockquote>
<p class="align-center"><em>¡Anímate a explorar y crear tus propias experiencias interactivas con esta increíble herramienta!</em></p>
</blockquote>
<h4 id="mcetoc_1i7actnb73q">Ejemplo de uso</h4>
<ol>
<li>Ingrese a <a href="https://playground.raise.mit.edu/create/" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">PoseNet</a>.</li>
<li>Descargue el archivo <a href="https://willedtech.github.io/media/files/Deteniendo al Perrito.sb3">Deteniendo al Perrito.sb3</a></li>
<li>Cargue el archivo en la plataforma.</li>
<li>Inicie simulación en la Banderita Verde.</li>
<li>También puedes ingresar directamente desde el siguiente enlace: <a href="https://playground.raise.mit.edu/create/?project=https://willedtech.github.io/willedtech_PoseNet/projects/Deteniendo-al-Perrito.sb3" target="_blank" class="extlink extlink-icon-2 "  rel="noopener noreferrer">Deteniendo al perrito</a>.</li>
</ol>
            ]]>
        </content>
    </entry>
</feed>
